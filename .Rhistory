}}
diag(beta) = 0
# initial hyperparameter values
sigma0 = 1
p0 = .2
v_slab = 3
n_sim = 50
X1 = MASS::mvrnorm(n/2, rep(0, p+1), Var1)
X2 = MASS::mvrnorm(n/2, rep(0, p+1), Var2)
data_mat = rbind(X1, X2)
# compute weights
tau = 1  # bandwidth
D = matrix(1, n, n)
for(i in 1:n){
for(j in 1:n){
D[i, j] = dnorm(norm(Z[i, ] - Z[j, ], "2"), 0, tau)
}
}
for(i in 1:n){
D[, i] = n * (D[, i] / sum(D[, i])) #Scaling the weights so that they add up to n
}
# fit the n x p regression models
graphs = wpl_regression(data_mat, D, sigma0, p0, v_slab, n_threads = 1,
blas_threads = 1)
graphs = wpl_regression(data_mat, D, sigma0, p0, v_slab, n_threads = 1,
blas_threads = 4)
graphs
length(graphs)
graphs[[1]]
graphs[[2]]
as.vector(graphs[[1]])
plot(as.vector(graphs[[1]]), as.vector(graphs[[2]])
)
D
# library(future.apply)
library(data.table)
source("experiment/simulation.R")
setDTthreads(1)
# Discrete covariate, independent ------------------------------------------------------
set.seed(1)
n = 100
p = 10
Lam1 = c(3, 3, 3, 3, rep(0, p-3)) * 5 # For Z[i]=-0.1
Lam2 = Lam1 #Same lambda for both covariate levels, corresponds to covariate independent levels
Var1 = solve(Lam1 %*% t(Lam1) + diag(rep(10, p+1))) #covariance matrix for covariate level 1
Var2 = solve(Lam2 %*% t(Lam2) + diag(rep(10, p+1))) #covariance matrix for covariate level 2
# covariate matrix
Z = matrix(-.1*(1:n <= n/2)  + .1*(1:n > n/2), nrow = n, ncol = p, byrow = FALSE)
Z
# true graph
beta = matrix(0, p+1, p+1)
for(i in 1:(p+1)){
for(j in 1:(p+1)){
beta[i,j] = (Lam1[i] != 0 & Lam1[j] != 0)
}}
diag(beta) = 0
# initial hyperparameter values
sigma0 = 1
p0 = .2
v_slab = 3
n_sim = 50
X1 = MASS::mvrnorm(n/2, rep(0, p+1), Var1)
X2 = MASS::mvrnorm(n/2, rep(0, p+1), Var2)
data_mat = rbind(X1, X2)
tau = 1  # bandwidth
D = matrix(1, n, n)
for(i in 1:n){
for(j in 1:n){
D[i, j] = dnorm(norm(Z[i, ] - Z[j, ], "2"), 0, tau)
}
}
for(i in 1:n){
D[, i] = n * (D[, i] / sum(D[, i])) #Scaling the weights so that they add up to n
}
D
Z
D
tau = 1  # bandwidth
D = matrix(1, n, n)
for(i in 1:n){
for(j in 1:n){
D[i, j] = dnorm(norm(Z[i, ] - Z[j, ], "2"), 0, tau)
}
}
D
tau = 1  # bandwidth
D = matrix(1, n, n)
for(i in 1:n){
for(j in 1:n){
D[i, j] = dnorm(norm(Z[i, ] - Z[j, ], "2"), 0, tau)
}
}
for(i in 1:n){
D[, i] = n * (D[, i] / sum(D[, i])) #Scaling the weights so that they add up to n
}
D
sim_accuracy
graphs
D[1, ]
D[100, ]
D[2, ]
# library(future.apply)
library(data.table)
source("experiment/simulation.R")
setDTthreads(1)
# Parallel control --------------------------------------------------------
# library(future.apply)
# library(doFuture)
library(doRNG)
registerDoFuture()
plan(multisession, workers = 8)
progressr::handlers("progress")
# RhpcBLASctl::blas_set_num_threads(1)
# Discrete covariate, independent ------------------------------------------------------
set.seed(1)
n = 100
p = 10
Lam1 = c(3, 3, 3, 3, rep(0, p-3)) * 5 # For Z[i]=-0.1
Lam2 = Lam1 #Same lambda for both covariate levels, corresponds to covariate independent levels
Var1 = solve(Lam1 %*% t(Lam1) + diag(rep(10, p+1))) #covariance matrix for covariate level 1
Var2 = solve(Lam2 %*% t(Lam2) + diag(rep(10, p+1))) #covariance matrix for covariate level 2
# covariate matrix
Z = matrix(-.1*(1:n <= n/2)  + .1*(1:n > n/2), nrow = n, ncol = p, byrow = FALSE)
# true graph
beta = matrix(0, p+1, p+1)
for(i in 1:(p+1)){
for(j in 1:(p+1)){
beta[i,j] = (Lam1[i] != 0 & Lam1[j] != 0)
}}
diag(beta) = 0
# initial hyperparameter values
sigma0 = 1
p0 = .2
v_slab = 3
n_sim = 2
progressr::with_progress({
prog = progressr::progressor(along = 1:n_sim)
sim_accuracy = rbindlist(
future_lapply(1:n_sim, function(sim_idx) {
prog(sprintf("Simulation %g, %s", sim_idx, Sys.time()))
# simulate the data for this iteration
X1 = MASS::mvrnorm(n/2, rep(0, p+1), Var1)
X2 = MASS::mvrnorm(n/2, rep(0, p+1), Var2)
data_mat = rbind(X1, X2)
# compute weights
tau = 1  # bandwidth
D = matrix(1, n, n)
for(i in 1:n){
for(j in 1:n){
D[i, j] = dnorm(norm(Z[i, ] - Z[j, ], "2"), 0, tau)
}
}
for(i in 1:n){
D[, i] = n * (D[, i] / sum(D[, i])) #Scaling the weights so that they add up to n
}
# fit the n x p regression models
graphs = wpl_regression(data_mat, D, sigma0, p0, v_slab, n_threads = 1,
blas_threads = 1)
# compute accuracy metrics
metrics = rbindlist(
foreach(individual = 1:length(graphs)) %do% {
graph = graphs[[individual]]
# symmetrize estimated graph
for(i in 1:(p+1)) {
for(j in i:(p+1)) {
graph[i, j] = mean(c(graph[i, j], graph[j, i]))
graph[j, i] = graph[i, j]
}
}
est_graph = 1 * (graph > 0.5)
data.table(
sensitivity = sum(est_graph & beta) / sum(beta),
specificity = sum(!est_graph & !beta) / sum(!beta),
individual = individual,
simulation = sim_idx
)
}
)
return(metrics)
}, future.seed = TRUE)
)
})
filename = paste0("data/", Sys.Date(), "_covariate_independent.RDS")
saveRDS(sim_accuracy, file = filename)
# library(future.apply)
library(data.table)
source("experiment/simulation.R")
setDTthreads(1)
# Parallel control --------------------------------------------------------
# library(future.apply)
# library(doFuture)
library(doRNG)
registerDoFuture()
plan(multisession, workers = 4)
progressr::handlers("progress")
# RhpcBLASctl::blas_set_num_threads(1)
# Discrete covariate, independent ------------------------------------------------------
set.seed(1)
n = 100
p = 10
Lam1 = c(3, 3, 3, 3, rep(0, p-3)) * 5 # For Z[i]=-0.1
Lam2 = Lam1 #Same lambda for both covariate levels, corresponds to covariate independent levels
Var1 = solve(Lam1 %*% t(Lam1) + diag(rep(10, p+1))) #covariance matrix for covariate level 1
Var2 = solve(Lam2 %*% t(Lam2) + diag(rep(10, p+1))) #covariance matrix for covariate level 2
# covariate matrix
Z = matrix(-.1*(1:n <= n/2)  + .1*(1:n > n/2), nrow = n, ncol = p, byrow = FALSE)
# true graph
beta = matrix(0, p+1, p+1)
for(i in 1:(p+1)){
for(j in 1:(p+1)){
beta[i,j] = (Lam1[i] != 0 & Lam1[j] != 0)
}}
diag(beta) = 0
# initial hyperparameter values
sigma0 = 1
p0 = .2
v_slab = 3
n_sim = 2
progressr::with_progress({
prog = progressr::progressor(along = 1:n_sim)
sim_accuracy = rbindlist(
future_lapply(1:n_sim, function(sim_idx) {
prog(sprintf("Simulation %g, %s", sim_idx, Sys.time()))
# simulate the data for this iteration
X1 = MASS::mvrnorm(n/2, rep(0, p+1), Var1)
X2 = MASS::mvrnorm(n/2, rep(0, p+1), Var2)
data_mat = rbind(X1, X2)
# compute weights
tau = 1  # bandwidth
D = matrix(1, n, n)
for(i in 1:n){
for(j in 1:n){
D[i, j] = dnorm(norm(Z[i, ] - Z[j, ], "2"), 0, tau)
}
}
for(i in 1:n){
D[, i] = n * (D[, i] / sum(D[, i])) #Scaling the weights so that they add up to n
}
# fit the n x p regression models
graphs = wpl_regression(data_mat, D, sigma0, p0, v_slab, n_threads = 1,
blas_threads = 1)
# compute accuracy metrics
metrics = rbindlist(
foreach(individual = 1:length(graphs)) %do% {
graph = graphs[[individual]]
# symmetrize estimated graph
for(i in 1:(p+1)) {
for(j in i:(p+1)) {
graph[i, j] = mean(c(graph[i, j], graph[j, i]))
graph[j, i] = graph[i, j]
}
}
est_graph = 1 * (graph > 0.5)
data.table(
sensitivity = sum(est_graph & beta) / sum(beta),
specificity = sum(!est_graph & !beta) / sum(!beta),
individual = individual,
simulation = sim_idx
)
}
)
return(metrics)
}, future.seed = TRUE)
)
})
filename = paste0("data/", Sys.Date(), "_covariate_independent.RDS")
saveRDS(sim_accuracy, file = filename)
sim_accuracy
sim_accuracy[individual == 1]
sim_accuracy[individual == 2]
sim_accuracy[individual == 3]
sim_accuracy[individual == 4]
sim_accuracy[individual == 5]
sim_accuracy[individual == 6]
sim_accuracy[individual == 7]
sim_accuracy[individual == 100]
library(doRNG)
registerDoFuture()
plan(multisession, workers = 4)
progressr::handlers("progress")
# RhpcBLASctl::blas_set_num_threads(1)
# Discrete covariate, independent ------------------------------------------------------
set.seed(1)
n = 100
p = 10
Lam1 = c(3, 3, 3, 3, rep(0, p-3)) * 5 # For Z[i]=-0.1
Lam2 = Lam1 #Same lambda for both covariate levels, corresponds to covariate independent levels
Var1 = solve(Lam1 %*% t(Lam1) + diag(rep(10, p+1))) #covariance matrix for covariate level 1
Var2 = solve(Lam2 %*% t(Lam2) + diag(rep(10, p+1))) #covariance matrix for covariate level 2
# covariate matrix
Z = matrix(-.1*(1:n <= n/2)  + .1*(1:n > n/2), nrow = n, ncol = p, byrow = FALSE)
# true graph
beta = matrix(0, p+1, p+1)
for(i in 1:(p+1)){
for(j in 1:(p+1)){
beta[i,j] = (Lam1[i] != 0 & Lam1[j] != 0)
}}
diag(beta) = 0
# initial hyperparameter values
sigma0 = 1
p0 = .2
v_slab = 3
n_sim = 2
progressr::with_progress({
prog = progressr::progressor(along = 1:n_sim)
sim_accuracy = rbindlist(
foreach(sim_idx = 1:n_sim, .combine = rbind) %dorng% {
# future_lapply(1:n_sim, function(sim_idx) {
prog(sprintf("Simulation %g, %s", sim_idx, Sys.time()))
# simulate the data for this iteration
X1 = MASS::mvrnorm(n/2, rep(0, p+1), Var1)
X2 = MASS::mvrnorm(n/2, rep(0, p+1), Var2)
data_mat = rbind(X1, X2)
# compute weights
tau = 1  # bandwidth
D = matrix(1, n, n)
for(i in 1:n){
for(j in 1:n){
D[i, j] = dnorm(norm(Z[i, ] - Z[j, ], "2"), 0, tau)
}
}
for(i in 1:n){
D[, i] = n * (D[, i] / sum(D[, i])) #Scaling the weights so that they add up to n
}
# fit the n x p regression models
graphs = wpl_regression(data_mat, D, sigma0, p0, v_slab, n_threads = 1,
blas_threads = 1)
# compute accuracy metrics
metrics = rbindlist(
foreach(individual = 1:length(graphs)) %do% {
graph = graphs[[individual]]
# symmetrize estimated graph
for(i in 1:(p+1)) {
for(j in i:(p+1)) {
graph[i, j] = mean(c(graph[i, j], graph[j, i]))
graph[j, i] = graph[i, j]
}
}
est_graph = 1 * (graph > 0.5)
data.table(
sensitivity = sum(est_graph & beta) / sum(beta),
specificity = sum(!est_graph & !beta) / sum(!beta),
individual = individual,
simulation = sim_idx
)
}
)
return(metrics)
# }, future.seed = TRUE)
}
)
})
library(data.table)
source("experiment/simulation.R")
setDTthreads(1)
# Parallel control --------------------------------------------------------
# library(future.apply)
# library(doFuture)
library(doRNG)
registerDoFuture()
plan(multisession, workers = 4)
progressr::handlers("progress")
# RhpcBLASctl::blas_set_num_threads(1)
# Discrete covariate, independent ------------------------------------------------------
set.seed(1)
n = 100
p = 10
Lam1 = c(3, 3, 3, 3, rep(0, p-3)) * 5 # For Z[i]=-0.1
Lam2 = Lam1 #Same lambda for both covariate levels, corresponds to covariate independent levels
Var1 = solve(Lam1 %*% t(Lam1) + diag(rep(10, p+1))) #covariance matrix for covariate level 1
Var2 = solve(Lam2 %*% t(Lam2) + diag(rep(10, p+1))) #covariance matrix for covariate level 2
# covariate matrix
Z = matrix(-.1*(1:n <= n/2)  + .1*(1:n > n/2), nrow = n, ncol = p, byrow = FALSE)
# true graph
beta = matrix(0, p+1, p+1)
for(i in 1:(p+1)){
for(j in 1:(p+1)){
beta[i,j] = (Lam1[i] != 0 & Lam1[j] != 0)
}}
diag(beta) = 0
# initial hyperparameter values
sigma0 = 1
p0 = .2
v_slab = 3
n_sim = 2
progressr::with_progress({
prog = progressr::progressor(along = 1:n_sim)
sim_accuracy = rbindlist(
foreach(sim_idx = 1:n_sim) %dorng% {
# future_lapply(1:n_sim, function(sim_idx) {
prog(sprintf("Simulation %g, %s", sim_idx, Sys.time()))
# simulate the data for this iteration
X1 = MASS::mvrnorm(n/2, rep(0, p+1), Var1)
X2 = MASS::mvrnorm(n/2, rep(0, p+1), Var2)
data_mat = rbind(X1, X2)
# compute weights
tau = 1  # bandwidth
D = matrix(1, n, n)
for(i in 1:n){
for(j in 1:n){
D[i, j] = dnorm(norm(Z[i, ] - Z[j, ], "2"), 0, tau)
}
}
for(i in 1:n){
D[, i] = n * (D[, i] / sum(D[, i])) #Scaling the weights so that they add up to n
}
# fit the n x p regression models
graphs = wpl_regression(data_mat, D, sigma0, p0, v_slab, n_threads = 1,
blas_threads = 1)
# compute accuracy metrics
metrics = rbindlist(
foreach(individual = 1:length(graphs)) %do% {
graph = graphs[[individual]]
# symmetrize estimated graph
for(i in 1:(p+1)) {
for(j in i:(p+1)) {
graph[i, j] = mean(c(graph[i, j], graph[j, i]))
graph[j, i] = graph[i, j]
}
}
est_graph = 1 * (graph > 0.5)
data.table(
sensitivity = sum(est_graph & beta) / sum(beta),
specificity = sum(!est_graph & !beta) / sum(!beta),
individual = individual,
simulation = sim_idx
)
}
)
return(metrics)
# }, future.seed = TRUE)
}
)
})
sim_accuracy
sim_accuracy[individual == 1]
cov_indep = readRDS("data/2021-05-29_covariate_independent.RDS")
cov_indep
cov_indep[simulation == 1]
cov_indep[simulation == 2]
cov_indep[simulation == 3]
cov_indep[simulation == 4]
cov_indep[simulation == 5]
cov_indep[simulation == 6]
foo = future_sapply(1:10, function(x) rnorm(1))
foo = future_sapply(1:10, function(x) rnorm(1), )
foo = future_sapply(1:10, function(x) rnorm(1), future.seed=TRUE)
foo
foo = future_sapply(1:10, function(x) rnorm(1), future.seed=TRUE)
foo
foo = future_sapply(1:10, function(x) rnorm(1), future.seed=1)
foo
foo = future_sapply(1:10, function(x) rnorm(1), future.seed=1)
foo
foo = future_sapply(1:10, function(x) rnorm(1), future.seed=2)
foo
p = 10
Lam1 = c(3, 3, 3, 3, rep(0, p-3)) * 5 # For Z[i]=-0.1
Lam2 = c(rep(0, p-3), 3, 3, 3, 3) * 5
Var1 = solve(Lam1 %*% t(Lam1) + diag(rep(10, p+1))) #covariance matrix for covariate level 1
Var2 = solve(Lam2 %*% t(Lam2) + diag(rep(10, p+1))) #covariance matrix for covariate level 2
# covariate matrix
Z = matrix(-.1*(1:n <= n/2)  + .1*(1:n > n/2), nrow = n, ncol = p, byrow = FALSE)
Z
# true graphs
beta_neg = matrix(0, p+1, p+1)
for(i in 1:(p+1)){
for(j in 1:(p+1)){
beta_neg[i,j] = (Lam1[i] != 0 & Lam1[j] != 0)
}}
diag(beta_neg) = 0
beta_pos = matrix(0, nrow = p+1, ncol = p+1)
for(i in 1:(p+1)){
for(j in 1:(p+1)){
beta_pos[i,j] = (Lam2[i] != 0 & Lam2[j] != 0)
}}
diag(beta_pos) = 0
sigma0 = 1
p0 = .2
v_slab = 3
tau = 1  # bandwidth
n_sim = 50
n_sim = 2
X1 = MASS::mvrnorm(n/2, rep(0, p+1), Var1)
X2 = MASS::mvrnorm(n/2, rep(0, p+1), Var2)
data_mat = rbind(X1, X2)
# compute weights
D = matrix(1, n, n)
for(i in 1:n){
for(j in 1:n){
D[i, j] = dnorm(norm(Z[i, ] - Z[j, ], "2"), 0, tau)
}
}
for(i in 1:n){
D[, i] = n * (D[, i] / sum(D[, i])) # Scaling the weights so that they add up to n
}
D
Z
X1 = MASS::mvrnorm(n/2, rep(0, p+1), Var1)
X2 = MASS::mvrnorm(n/2, rep(0, p+1), Var2)
data_mat = rbind(X1, X2)
# compute weights
D = matrix(1, n, n)
for(i in 1:n){
for(j in 1:n){
D[i, j] = dnorm(norm(Z[i, ] - Z[j, ], "2"), 0, tau)
}
}
for(i in 1:n){
D[, i] = n * (D[, i] / sum(D[, i])) # Scaling the weights so that they add up to n
}
D
